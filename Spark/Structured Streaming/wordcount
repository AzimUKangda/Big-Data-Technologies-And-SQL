package com.spark.test.structuredstreaming

import org.apache.spark.sql.SparkSession

object streamingDemo {

  def main(args: Array[String]): Unit = {

    val spark = SparkSession.builder().master("local").getOrCreate()

    spark.sparkContext.setLogLevel("ERROR")

    val lines = spark.readStream
      .format("text")
      .option(
        "path",
        "C:\\Users\\Azim Kangda\\IdeaProjects\\NetworkAnalysisDemo\\src\\main\\resources\\data\\streaming")
      .option("maxFilesPerTrigger", 2)
      .load()

    import spark.implicits._

    val words = lines.as[String].flatMap(_.split(" "))

    val wordCount = words.groupBy("value").count()

    val query =
      wordCount.writeStream.outputMode("complete").format("console").start()

    query.awaitTermination()

  }

}
